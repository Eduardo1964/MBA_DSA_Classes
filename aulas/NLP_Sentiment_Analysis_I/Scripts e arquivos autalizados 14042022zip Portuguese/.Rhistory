pacotes <- c("tidytext","ggplot2","dplyr")
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
#Pacotes
library("dplyr")
library("tidytext")
library("ggplot2")
?tidytext
st <- starwars
?starwars
View(st)
library("tibble")
View(st)
filtro <- starwars %>%  filter(species == "Droid")
View(filtro)
select <- starwars %>%  select(name, ends_with("color"))
View(select)
#Pacotes
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
st <- starwars
filtro <- starwars %>%  filter(species == "Droid")
select <- starwars %>%  select(name, ends_with("color"))
View(select)
View(st)
select <- starwars %>%  select(name)
View(select)
?ends_with
View(select)
select <- starwars %>%  select(name, ends_with("color"))
View(select)
imc <- starwars %>%   mutate(name, altura = height / 100) %>%  select(name:mass, altura)
View(imc)
imc <- starwars %>%   mutate(name, altura = height / 100)
View(imc)
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
text <- c("E quando falo em aceitar a vida nao me refiro a aceita lo resignada e passiva",
"de todas as desigualdades, malvadezas, absurdos e miserias do mundo.",
"Refiro-me, sim, a aceita lo da luta necessaria, do sofrimento que essa luta nos trara,",
"das horas amargas a que ela forcosamente nos ha de levar.")
text
dim(text)
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:4, text = text)
View(text_df)
?unnest_tokens
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
View(df)
?stop_words
stop_words
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
text <- c("From my infancy I was noted for the docility and humanity of my disposition.",
"My tenderness of heart was even so conspicuous as to make me the jest of my companions.",
"I was especially fond of animals, and was indulged by my parents with a great variety of pets.")
text
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:4, text = text)
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:3, text = text)
View(text_df)
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
View(df)
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
st <- starwars
#Pequena introducao ao dplyr
filtro <- starwars %>%  filter(species == "Droid")
select <- starwars %>%  select(name, ends_with("color"))
imc <- starwars %>%   mutate(name, altura = height / 100)
#Texto de Edgar Allan Poe - the black cat
text <- c("From my infancy I was noted for the docility and humanity of my disposition.",
"My tenderness of heart was even so conspicuous as to make me the jest of my companions.",
"I was especially fond of animals, and was indulged by my parents with a great variety of pets.")
text
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:3, text = text)
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
stop_words
View(df)
df_sem_stop_words <- df %>% anti_join(stop_words)
View(df_sem_stop_words)
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
text <- c("From my infancy I was noted for the docility and humanity of my disposition.",
"My tenderness of heart was even so conspicuous as to make me the jest of my companions.",
"I was especially fond of animals, and was indulged by my parents with a great variety of pets.",
"With these I spent most of my time, and never was so happy as when feeding and caressing them.")
text
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:4, text = text)
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
stop_words
df_sem_stop_words <- df %>% anti_join(stop_words)
conta <- df_sem_stop_words %>%  count(word, sort = TRUE)
View(conta)
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
text <- c("From my infancy I was noted for the docility and humanity of my disposition.",
"My tenderness of heart was even so conspicuous as to make me the jest of my companions.",
"I was especially fond of animals, and was indulged by my parents with a great variety of pets.",
"With these I spent most of my time, and never was so happy as when feeding and caressing them.",
"This peculiarity of character grew with my growth, and, in my manhood, I derived from it one of my principal sources of pleasure.",
"To those who have cherished an affection for a faithful and sagacious dog, I need hardly be at the trouble of explaining the nature or the intensity of the gratification thus derivable.",
"There is something in the unselfish and self-sacrificing love of a brute, which goes directly to the heart of him who has had frequent occasion to test the paltry friendship and gossamer fidelity of mere Man.")
text
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:7, text = text)
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
stop_words
df_sem_stop_words <- df %>% anti_join(stop_words)
conta <- df_sem_stop_words %>%  count(word, sort = TRUE)
View(conta)
#grafico
df_sem_stop_words %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col()
#Para facilitar a visualização
df_conta <- df_sem_stop_words[1:20]
#Para facilitar a visualização
df_conta <- df_sem_stop_words[1:20,2]
View(df_conta)
df_conta %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col()
View(df_conta)
View(conta)
conta
#Para facilitar a visualização
df_conta <- df_sem_stop_words[0:20,2]
View(df_conta)
df_conta %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col()
View(df_sem_stop_words)
#Para facilitar a visualização
df_conta <- df_sem_stop_words[0:30,2]
df_conta %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col()
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
text <- c("From my infancy I was noted for the docility and humanity of my disposition.",
"My tenderness of heart was even so conspicuous as to make me the jest of my companions.",
"There is something in the unselfish and self-sacrificing love of a brute, which goes directly to the heart of him who has had frequent occasion to test the paltry friendship and gossamer fidelity of mere Man.")
text
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:3, text = text)
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
df_sem_stop_words <- df %>% anti_join(stop_words)
conta <- df_sem_stop_words %>%  count(word, sort = TRUE)
View(conta)
df_sem_stop_words %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col()
library("dplyr")
library("tidytext")
library("ggplot2")
library("tibble")
text <- c("From my infancy I was noted for the docility and humanity of my disposition.",
"My tenderness of heart was even so conspicuous as to make me the jest of my companions.",
"There is something in the unselfish and self-sacrificing love of a brute, which goes directly to the heart of him who has had frequent occasion to test the paltry friendship and gossamer fidelity of mere Man.")
text
#Uso do formato tibble e explicacao
text_df <- tibble(line = 1:3, text = text)
#Explicao de token
#Abre funcao e explica unnest_tokens
#?unnest_tokens
df <-  text_df %>% unnest_tokens(word, text)
stop_words
df_sem_stop_words <- df %>% anti_join(stop_words)
conta <- df_sem_stop_words %>%  count(word, sort = TRUE)
df_sem_stop_words %>%
count(word, sort = TRUE) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(n, word)) +
geom_col()
View(df_sem_stop_words)
library("gutenbergr")
library("dplyr")
library("tidytext")
library("wordcloud")
library("stringr")
library("SnowballC")
?gutenberg_metadata
textos <- gutenberg_metadata
View(textos)
#Vamos usar perter pan e Moby Dick
livros <- gutenberg_download(c(15,16))
View(livros)
View(textos)
View(textos)
View(livros)
?str_detect
View(textos)
View(livros)
livros %>% filter(str_detect(text, "^[0-9]"))
#Vamos retirar números - pode ser qualquer coisa
nums <- livros %>% filter(str_detect(text, "^[0-9]")) %>% select(text) %>% unique()
View(nums)
nums <- livros %>% filter(str_detect(text, "^[0-9]")) %>% select(text)
#Vamos retirar números - pode ser qualquer coisa
nums <- livros %>% filter(str_detect(text, "^[0-9]")) %>% select(text)
livros <- livros %>%  anti_join(nums, by = "text")
#Vamos nos livrar das stop words e obter os tokens
livros <- livros %>%  unnest_tokens(word, text) %>%  anti_join(stop_words)
View(livros)
View(livros)
#Moby Dick
moby <- livros %>% filter(gutenberg_id == 15) %>% count(word, sort = TRUE)
View(moby)
# define a paleta de cores
pal <- brewer.pal(8,"Dark2")
?with
# word cloud
moby %>% wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal)
# word cloud
moby %>% with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
?with
# word cloud
moby %>% with(wordcloud(word, n, max.words = 50, colors=pal))
# word cloud
moby %>% with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
?wordcloud
?brewer.pal
View(moby)
?wordcloud
# word cloud
moby %>% with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
library("gutenbergr")
library("dplyr")
library("tidytext")
library("wordcloud")
library("stringr")
library("SnowballC")
textos <- gutenberg_metadata
#Vamos usar perter pan e Moby Dick
livros <- gutenberg_download(c(15,16))
#Peter Pan
peter <- livros %>% filter(gutenberg_id == 16) %>% count(word, sort = TRUE)
#Vamos retirar números - pode ser qualquer coisa
nums <- livros %>% filter(str_detect(text, "^[0-9]")) %>% select(text)
livros <- livros %>%  anti_join(nums, by = "text")
#Vamos nos livrar das stop words e obter os tokens
livros <- livros %>%  unnest_tokens(word, text) %>%  anti_join(stop_words)
#Peter Pan
peter <- livros %>% filter(gutenberg_id == 16) %>% count(word, sort = TRUE)
# define a paleta de cores
pal <- brewer.pal(8,"Dark2")
# word cloud
peter %>% with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
#Stemming - vamos aplicar
peter_stem <-  peter %>%  mutate(stem = wordStem(word))
peter_stem_count <- livros %>% filter(gutenberg_id == 16) %>% mutate(stem = wordStem(word)) %>% count(stem, sort = TRUE)
View(peter_stem_count)
View(peter_stem)
peter_stem_count <- livros %>% filter(gutenberg_id == 16) %>% mutate(stem = wordStem(word)) %>% count(stem, sort = TRUE)
View(peter_stem_count)
?stringi
library("gutenbergr")
library("dplyr")
library("tidytext")
library("wordcloud")
library("stringr")
library("SnowballC")
textos <- gutenberg_metadata
textos$language == 'sp'
#Vamos usar perter pan e Moby Dick
livro <- gutenberg_download(c(33752))
#Mudamos o encoding para ver os acentos
#Discutir o que é encoding: https://blog.caelum.com.br/entendendo-unicode-e-os-character-encodings/amp/
Encoding(livro$text) <- "ASCII"
#vamos retirar os acentos
for (i in 1:nrow(livro))
{
livro$text[i] <- iconv(livro$text[i], to = "ASCII//TRANSLIT")
}
#Unnest tokens
livro <- livro %>%  unnest_tokens(word, text)
#Excluímos stop words em português - instalar stop words
livro <- livro %>% anti_join(get_stopwords(language = 'pt'))
#Aplicaremos o setemming
livro_stem <-  livro %>%  mutate(stem = wordStem(word))
#Word cloud - teste word e stem
livro_cont <- livro_stem %>% select(word) %>% count(word, sort = TRUE)
pal <- brewer.pal(8,"Dark2")
livro_cont %>% with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
library("gutenbergr")
library("dplyr")
library("tidytext")
library("wordcloud")
library("stringr")
library("SnowballC")
textos <- gutenberg_metadata
textos$language == 'sp'
gutenberg_download(c(33752))
textos$language == 'pt'
View(textos)
#Segundo test - Project Gutenberg
#install.packages("gutenbergr")
library("gutenbergr")
library("dplyr")
library("tidytext")
library("wordcloud")
library("stringr")
library("SnowballC")
#install.packages("stopwords")
textos <- gutenberg_metadata
textos$language == 'pt'
#Vamos usar os netos de camilo
livro <- gutenberg_download(c(33752))
View(livro)
#Mudamos o encoding para ver os acentos
#Discutir o que é encoding: https://blog.caelum.com.br/entendendo-unicode-e-os-character-encodings/amp/
Encoding(livro$text) <- "ASCII"
View(livro)
View(livro)
?iconv
for (i in 1:nrow(livro))
{
livro$text[i] <- iconv(livro$text[i], to = "ASCII//TRANSLIT")
}
View(livro)
#Unnest tokens
livro <- livro %>%  unnest_tokens(word, text)
View(livro)
?get_stopwords
#Excluímos stop words em português - instalar stop words
livro <- livro %>% anti_join(get_stopwords(language = 'pt'))
View(livro)
?wordStem
#Aplicaremos o setemming
livro_stem <-  livro %>%  mutate(stem = wordStem(word))
View(livro_stem)
#Word cloud - teste word e stem
livro_cont <- livro_stem %>% select(word) %>% count(word, sort = TRUE)
View(livro_cont)
pal <- brewer.pal(8,"Dark2")
livro_cont %>% with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
#Segundo test - Project Gutenberg
#install.packages("gutenbergr")
library("gutenbergr")
library("dplyr")
library("tidytext")
library("wordcloud")
library("stringr")
library("SnowballC")
#install.packages("stopwords")
textos <- gutenberg_metadata
#Vamos usar última ceia do dr fausto
livro <- gutenberg_download(c(35982))
#Mudamos o encoding para ver os acentos
#Discutir o que é encoding: https://blog.caelum.com.br/entendendo-unicode-e-os-character-encodings/amp/
Encoding(livro$text) <- "ASCII"
#vamos retirar os acentos
for (i in 1:nrow(livro))
{
livro$text[i] <- iconv(livro$text[i], to = "ASCII//TRANSLIT")
}
#Unnest tokens - vamos fazer n gramas de 2 = bigrama
livro <- livro %>%  unnest_tokens(word, text, token = "ngrams", n = 2)
#VAMOS CONTAR
cont <- livro %>% count(word, sort = TRUE)
View(cont)
library("widyr")
library("janeaustenr")
austen_section_words <- austen_books() %>%
filter(book == "Pride & Prejudice") %>%
mutate(section = row_number() %/% 10) %>%
filter(section > 0) %>%
unnest_tokens(word, text) %>%
filter(!word %in% stop_words$word)
word_pairs <- austen_section_words %>%
pairwise_count(word, section, sort = TRUE)
View(word_pairs)
word_cors <- austen_section_words %>%
group_by(word) %>%
filter(n() >= 20) %>%
pairwise_cor(word, section, sort = TRUE)
View(word_cors)
