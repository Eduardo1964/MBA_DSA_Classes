levels(HAR_train$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
levels(HAR_test$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
tempo_ini <- Sys.time()
c_test <- predict(rf, HAR_test)
c_test[1:10]
avalia <- function(modelo, nome_modelo="modelo", df_treino, df_teste, vresp = "y"){
p_treino <- predict(modelo, df_treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, df_treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, df_teste, type='prob')
c_teste <- predict(modelo, df_teste)
cm_treino <- confusionMatrix(c_treino, df_treino[,vresp])
print(cm_treino$table)
print(cm_treino$overall["Accuracy"])
cm_teste <- confusionMatrix(c_teste,  df_teste[,vresp])
print(cm_teste$table)
print(cm_teste$overall['Accuracy'])
}
avalia(rf, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
rf$importance
variaveis_selecionadas <- rf$importance %>% as.data.frame() %>% top_n(6) %>% row.names
variaveis_selecionadas
HAR_train$y %>% table
# função para padronizar
range01 <- function(x){(x-min(x, na.rm=TRUE))/(max(x, na.rm=TRUE)-min(x, na.rm=TRUE))}
# padronizar variaveis quantitativas
HAR_train[variaveis_selecionadas] <- lapply(HAR_train[variaveis_selecionadas], range01)
nnGrid <-  expand.grid(.size=7, .decay = c(0))
# nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025))
ctrl <- caret::trainControl(method='cv', classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
?caret::trainControl
# nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .010, 0.015, 0.020, 0.025))
ctrl <- caret::trainControl(method='cv', number=4, classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1500,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=500,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .010, 0.015))
ctrl <- caret::trainControl(method='cv', number=4, classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=500,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .010, 0.015))
ctrl <- caret::trainControl(method='cv', number=4, classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=5000,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
load("/Volumes/GoogleDrive-105296192289087716243/Meu Drive/Pecege/OMML3/OMML3_ANN/HAR_train.RData")
load("/Volumes/GoogleDrive-105296192289087716243/Meu Drive/Pecege/OMML3/OMML3_ANN/HAR_test.RData")
levels(HAR_train$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
levels(HAR_test$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
rf <- randomForest(y ~ .,
data=HAR_train[,2:563],
ntree=20,
mtry=100)
rf
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
c_test <- predict(rf, HAR_test)
c_test[1:10]
######################
# Função para avaliar o modelo
avalia <- function(modelo, nome_modelo="modelo", df_treino, df_teste, vresp = "y"){
p_treino <- predict(modelo, df_treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, df_treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, df_teste, type='prob')
c_teste <- predict(modelo, df_teste)
cm_treino <- confusionMatrix(c_treino, df_treino[,vresp])
print(cm_treino$table)
print(cm_treino$overall["Accuracy"])
cm_teste <- confusionMatrix(c_teste,  df_teste[,vresp])
print(cm_teste$table)
print(cm_teste$overall['Accuracy'])
}
avalia(rf, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
rf$importance
variaveis_selecionadas <- rf$importance %>% as.data.frame() %>% top_n(6) %>% row.names
variaveis_selecionadas
HAR_train$y %>% table
nnGrid <-  expand.grid(.size=6, .decay = c(0))
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .010, 0.015))
ctrl <- caret::trainControl(method='cv', number=4, classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=5000,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
save(df, 'EPA_19.RData')
save(df, file='EPA_19.RData')
# carregar os dados
load(file='EPA_19.RData')
pacotes <- c('tidyverse',  # Pacote básico de datawrangling
'viridis',
'rpart',      # Biblioteca de árvores
'rpart.plot', # Conjunto com Rpart, plota a parvore
'gtools',     # funções auxiliares como quantcut,
'Rmisc',      # carrega a função sumarySE para a descritiva
'scales',     # importa paletas de cores
'caret',      # Funções úteis para machine learning
'neuralnet',   # Pacote para fazer redes neurais
'gamlss',
'gamlss.add'
)
if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
instalador <- pacotes[!pacotes %in% installed.packages()]
for(i in 1:length(instalador)) {
install.packages(instalador, dependencies = T)
break()}
sapply(pacotes, require, character = T)
} else {
sapply(pacotes, require, character = T)
}
load('EPA_19.RData')
load('HAR_test.RData')
load('HAR_train.RData')
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
x1 <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 12.5
c <- -10
set.seed(2360873)
y1 <- a + b*x1 + c*x1**2 + rnorm(length(x1), mean=0, sd=.1)
df1 <- data.frame(x1, y1)
colnames(df1) <- c('x', 'y')
# Gráfico dos dados gerados
p0 <- ggplot(df1, aes(x,y)) +
geom_point(aes(colour='Observado'), alpha=.5) +
viridis::scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme_bw() +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
# Primeira rede neural
rn0 <- neuralnet::neuralnet(y ~ x,
data=df1,
threshold = 0.01,
act.fct = 'logistic'
)
plot(rn0)
df1['pred0'] <- predict(rn0, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred0, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
# theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
# scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
rn1 <- neuralnet(y ~ x,
data=df1,
hidden = c(3,2))
plot(rn1)
tempo_ini <- Sys.time()
rn1 <- neuralnet(y ~ x,
data=df1,
hidden = c(3,2))
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
plot(rn1)
df1['pred1'] <- predict(rn1, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred1, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
df1['pred1'] <- predict(rn1, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) + # gráfico base >> x vs y <<
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred1, colour='Esperado')) + # Gráfico sobreposto >> x vs pred
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
tempo_ini <- Sys.time()
rn1 <- neuralnet(y ~ x,
data=df1,
hidden = c(3,2))
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
plot(rn1)
df1['pred1'] <- predict(rn1, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) + # gráfico base >> x vs y <<
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred1, colour='Esperado')) + # Gráfico sobreposto >> x vs pred
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# Primeira rede neural
set.seed(1729)
rn0 <- neuralnet::neuralnet(y ~ x,
data=df1,
threshold = 0.01,
act.fct = 'logistic'
)
plot(rn0)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred0, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
# theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
# scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# Gerar x como uma sequencia de valores entre 0 e 1
x1 <- seq(0,1, length.out=1000)
# y segue uma relação quadrática com estes parâmetros
a <- 0
b <- 12.5
c <- -10
# Gerar y
set.seed(1729)
y1 <- a + b*x1 + c*x1**2 + rnorm(length(x1), mean=0, sd=.1)
df1 <- data.frame(x1, y1) # criar um dataframe
colnames(df1) <- c('x', 'y') #renomear colunas
# Gráfico dos dados gerados
p0 <- ggplot(df1, aes(x,y)) +
geom_point(aes(colour='Observado'), alpha=.5) +
viridis::scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme_bw() +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
# Primeira rede neural
set.seed(1729)
rn0 <- neuralnet::neuralnet(y ~ x,
data=df1,
threshold = 0.01,
act.fct = 'logistic'
)
plot(rn0)
df1['pred0'] <- predict(rn0, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred0, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
# theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
# scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
########################
# Perceptron Multicamada
set.seed(1729)
tempo_ini <- Sys.time()
rn1 <- neuralnet(y ~ x,
data=df1,
hidden = c(3,2))
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
plot(rn1)
df1['pred1'] <- predict(rn1, df1)
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df1, aes(x,y)) + # gráfico base >> x vs y <<
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,pred1, colour='Esperado')) + # Gráfico sobreposto >> x vs pred
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# carregar os dados
load(file='EPA_19.RData')
# checar a estrutura
df %>% str
# colunas quantitativas para padronizar entre 0 e 1
cols <- c("fuel_economy_combined", 'eng_disp', 'num_cyl', 'num_gears', 'batt_capacity_ah')
# função para padronizar
range01 <- function(x){(x-min(x, na.rm=TRUE))/(max(x, na.rm=TRUE)-min(x, na.rm=TRUE))}
# padronizar variaveis quantitativas
df[cols] <- lapply(df[cols], range01)
df %>% head
# criar a fórmula tipo y ~ x1 + x2 ... + xn
n <- names(df)
f_variaveis <- paste(n[-1], collapse = " + ")
f_variaveis
f <- as.formula(paste(n[1], " ~ ", f_variaveis))
f
df %>% str
m <- model.matrix(f, data = df)
m <- as.matrix(data.frame(m, df[, 1]))
#######################################
# Criar uma fórmula para a matriz m
colnames(m)[28] <- "fuel_economy_combined"
nomes <- colnames(m)
f_variaveis <- paste(nomes[-28], collapse=' + ')
f <- as.formula(paste(nomes[28], " ~ ", f_variaveis))
f
# Treinando um Linear Perceptron
start_time <- Sys.time() # Marca o tempo de início
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, # Fórmula
data=m, # dados
linear.output = TRUE # indica resposta contínua
)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
plot(nn)
set.seed(1729)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, # Fórmula
data=m, # dados
linear.output = TRUE # indica resposta contínua
)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
plot(nn)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, data=m2[ind_treino,], hidden = c(7, 3), linear.output = TRUE)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, data=m[ind_treino,], hidden = c(7, 3), linear.output = TRUE)
start_time <- Sys.time() # Marca o tempo de início
nn <- neuralnet(f, data=m, hidden = c(7, 3), linear.output = TRUE)
end_time <- Sys.time() # Marca o tempo de fim
t <- end_time - start_time # Mostra o tempo de execução
t
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
k <- 10 #número de folds
stats <- NULL # Inicializando a qualidade dos modelos do fold
m2 = m[sample(1:nrow(m)), ] # m2 é uma permutação de m para fazermos os folds
for (i in 1:(k-1)){
ind_treino <- !seq(N)>N*(i/k) & seq(N)<=N*((i+1)/k)
ind_teste <- seq(N)>N*(i/k) & seq(N)<=N*((i+1)/k)
nn <- neuralnet(f, data=m2[ind_treino,], hidden = c(7, 3), linear.output = TRUE)
pred <- predict(nn, m[ind_teste,])
stats_tmp <- caret::postResample(pred, df$fuel_economy_combined[ind_teste])
stats <- rbind(stats, stats_tmp)
}
stats %>% colMeans()
N <- nrow(m)
k <- 10 #número de folds
stats <- NULL # Inicializando a qualidade dos modelos do fold
m2 = m[sample(1:nrow(m)), ] # m2 é uma permutação de m para fazermos os folds
for (i in 1:(k-1)){
ind_treino <- !seq(N)>N*(i/k) & seq(N)<=N*((i+1)/k)
ind_teste <- seq(N)>N*(i/k) & seq(N)<=N*((i+1)/k)
nn <- neuralnet(f, data=m2[ind_treino,], hidden = c(7, 3), linear.output = TRUE)
pred <- predict(nn, m[ind_teste,])
stats_tmp <- caret::postResample(pred, df$fuel_economy_combined[ind_teste])
stats <- rbind(stats, stats_tmp)
}
stats %>% colMeans()
pred <- predict(nn, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025))
nnGrid <-  expand.grid(.size=7, .decay = c(0, .005, .01, 0.015, 0.02, 0.025))
?expand.grid
ctrl <- caret::trainControl(method='cv')
nnfit <- caret::train(f,
data=m2,
method='nnet',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=1000,
verboseIter = FALSE
)
nnfit$results
modelo.final <- nnfit$finalModel
pred <- predict(modelo.final, m)
plot(x = pred, y = df$fuel_economy_combined)
caret::postResample(pred, df$fuel_economy_combined)
levels(HAR_train$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
levels(HAR_test$y) <- c("andando",  "subindo", "descendo", "sentado",  "em_pe", "deitado")
tempo_ini <- Sys.time()
rf <- randomForest(y ~ .,
data=HAR_train[,2:563],
ntree=20,
mtry=100)
rf <- randomForest::randomForest(y ~ .,
data=HAR_train[,2:563],
ntree=20,
mtry=100)
rf
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
c_test <- predict(rf, HAR_test)
c_test[1:10]
avalia <- function(modelo, nome_modelo="modelo", df_treino, df_teste, vresp = "y"){
p_treino <- predict(modelo, df_treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, df_treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, df_teste, type='prob')
c_teste <- predict(modelo, df_teste)
cm_treino <- confusionMatrix(c_treino, df_treino[,vresp])
print(cm_treino$table)
print(cm_treino$overall["Accuracy"])
cm_teste <- confusionMatrix(c_teste,  df_teste[,vresp])
print(cm_teste$table)
print(cm_teste$overall['Accuracy'])
}
avalia(rf, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
rf$importance
variaveis_selecionadas <- rf$importance %>% as.data.frame() %>% top_n(6) %>% row.names
variaveis_selecionadas
HAR_train$y %>% table
nnGrid <-  expand.grid(.size=6, .decay = c(0))
ctrl <- caret::trainControl(method='cv', number=4, classProbs=TRUE)
nnfit <- caret::train(y ~ .,
data=HAR_train[,c(variaveis_selecionadas, 'y')],
method='nnet',
metric='Accuracy',
tuneGrid=nnGrid,
trControl=ctrl,
maxit=100,
verboseIter = FALSE
)
# Resultados do grid search
nnfit$results
avalia(nnfit, nome_modelo="rf", HAR_train, HAR_test, vresp = "y")
