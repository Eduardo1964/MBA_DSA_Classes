CurvaROC
}
avalia(treino_rf)
tcs_treino
tcs_teste
# Base de treino
avalia <- function(modelo){
rf_p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
rf_c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
rf_p_teste <- predict(modelo, teste, type='prob')
rf_c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
rf_aval_treino <- data.frame(obs=treino$Survived,
pred=rf_c_treino,
Y = rf_p_treino[,2],
N = 1-rf_p_treino[,2]
)
# Data frame de avaliação (Teste)
rf_aval_teste <- data.frame(obs=teste$Survived,
pred=rf_c_teste,
Y = rf_p_teste[,2],
N = 1-rf_p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(rf_aval_treino,
lev=levels(rf_aval_treino$obs))
tcs_teste <- caret::twoClassSummary(rf_aval_teste,
lev=levels(rf_aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(rf_aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=rf_aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
CurvaROC
tcs_treino
tcs_teste
}
avalia(treino_rf)
print(tcs_teste)
# Base de treino
avalia <- function(modelo){
rf_p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
rf_c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
rf_p_teste <- predict(modelo, teste, type='prob')
rf_c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
rf_aval_treino <- data.frame(obs=treino$Survived,
pred=rf_c_treino,
Y = rf_p_treino[,2],
N = 1-rf_p_treino[,2]
)
# Data frame de avaliação (Teste)
rf_aval_teste <- data.frame(obs=teste$Survived,
pred=rf_c_teste,
Y = rf_p_teste[,2],
N = 1-rf_p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(rf_aval_treino,
lev=levels(rf_aval_treino$obs))
tcs_teste <- caret::twoClassSummary(rf_aval_teste,
lev=levels(rf_aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(rf_aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=rf_aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
CurvaROC
print(tcs_treino)
print(tcs_teste)
}
avalia(treino_rf)
# Base de treino
avalia <- function(modelo){
p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, teste, type='prob')
c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
# Data frame de avaliação (Teste)
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(aval_treino,
lev=levels(aval_treino$obs))
tcs_teste <- caret::twoClassSummary(aval_teste,
lev=levels(aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
CurvaROC
print(tcs_treino)
print(tcs_teste)
}
avalia(treino_rf)
tempo_ini <- Sys.time()
# number: number of folds for training
# repeats: keep the number for training
# O objeto gerado por trainControl vai controlar o algoritmo
controle <- caret::trainControl(
method='repeatedcv', # Solicita um K-Fold com repetições
number=4, # Número de FOLDS (o k do k-fold)
repeats=2, # Número de repetições
search='grid', # especifica o grid-search
summaryFunction = twoClassSummary, # Função de avaliação de performance
classProbs = TRUE # Necessário para calcular a curva ROC
)
# agora vamos especificar o grid
grid <- base::expand.grid(.mtry=c(1:10))
# Vamos treinar todos os modelos do grid-search com cross-validation
gridsearch_rf <- caret::train(Survived ~ .,         # Fórmula (todas as variáveis)
data = treino,       # Base de dados
method = 'rf',        # Random-forest
metric='ROC',         # Escolhe o melhor por essa métrica
trControl = controle, # Parâmetros de controle do algoritmo
ntree=100,            # Numero de árvores
tuneGrid = grid)      # Percorre o grid especificado aqui
print(gridsearch_rf)
plot(gridsearch_rf)
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
avalia(gridsearch_rf)
# Base de treino
avalia <- function(modelo){
p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, teste, type='prob')
c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
# Data frame de avaliação (Teste)
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(aval_treino,
lev=levels(aval_treino$obs))
tcs_teste <- caret::twoClassSummary(aval_teste,
lev=levels(aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
CurvaROC
print('Avaliação base de treino')
print(tcs_treino)
print('Avaliação base de teste')
print(tcs_teste)
}
avalia(treino_rf)
# Base de treino
avalia <- function(modelo){
p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, teste, type='prob')
c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
# Data frame de avaliação (Teste)
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(aval_treino,
lev=levels(aval_treino$obs))
tcs_teste <- caret::twoClassSummary(aval_teste,
lev=levels(aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
print('Avaliação base de treino')
print(tcs_treino)
print('Avaliação base de teste')
print(tcs_teste)
CurvaROC
}
avalia(treino_rf)
avalia(gridsearch_rf)
rf_p_treino <- predict(gridsearch_rf, treino, type='prob') # Probabilidade predita
rf_c_treino <- predict(gridsearch_rf, treino)              # Classificação
#Base de teste
rf_p_teste <- predict(gridsearch_rf, teste, type='prob')
rf_c_teste <- predict(gridsearch_rf, teste)
# Data frame de avaliação (Treino)
rf_aval_treino <- data.frame(obs=treino$Survived,
pred=rf_c_treino,
Y = rf_p_treino[,2],
N = 1-rf_p_treino[,2]
)
# Data frame de avaliação (Teste)
rf_aval_teste <- data.frame(obs=teste$Survived,
pred=rf_c_teste,
Y = rf_p_teste[,2],
N = 1-rf_p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(rf_aval_treino,
lev=levels(rf_aval_treino$obs))
tcs_teste <- caret::twoClassSummary(rf_aval_teste,
lev=levels(rf_aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(rf_aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=rf_aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC Random Forest | AUC-treino=",
percent(tcs_treino[1], accuracy=0.1),
"| AUC_teste = ",
percent(tcs_teste[1], accuracy=0.1))
)
CurvaROC
avalia(gridsearch_rf)
#####
# Gerando os dados
# x é uma sequencia de valores entre 0 e 1
x <- seq(0,1, length.out=1000)
# y segue uma relação quadrática
a <- 0
b <- 10
c <- -10
set.seed(2360873)
y <- a + b*x + c*x**2 + rnorm(length(x), mean=0, sd=.1)
df <- data.frame(x, y)
p0 <- ggplot(df, aes(x,y)) +
geom_point(aes(colour='Observado')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.85, name = "Valor") +
theme(legend.position="bottom",
legend.spacing.x = unit(0, 'cm'))
p0
########################
# Construindo a árvore #
tree <- rpart(y~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
# Plotando a árvore
paleta = scales::viridis_pal(begin=.75, end=1)(20)
rpart.plot::rpart.plot(tree,
box.palette = paleta) # Paleta de cores
# Valores preditos
df['p'] = predict(tree, df)
df['r'] = df$y - df$p
# Valores esperados e observados
boost0_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
# guides(colour = guide_legend(label.position = "bottom")) +
labs(title="Valores observados vs esperados") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
boost0_O_vs_E
# Gráfico de resíduos
boost0_res <- ggplot(df, aes(x,r)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
theme_bw() +
theme(legend.position="bottom") +
labs(title="Gráfico de resíduos") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
boost0_res
ggpubr::ggarrange(boost0_O_vs_E, boost0_res,
# labels = c("A", "B"),
ncol = 2, nrow = 1)
# Primeira iteração de boosting manual
tree1 <- rpart(r~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
df['p1'] = predict(tree1, df)  # Predito da árvore neste passo
df['P1'] = df$p + df$p1        # Predito do boosting (acumulado)
df['r1'] = df$r - df$p1        # resíduo do boosting
# Gráfico da primeira iteração de boosting manual
# O QUE O MODELO ESTÁ FAZENDO
boost1_r_vs_E <- ggplot(df, aes(x,r)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p1, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Variável resposta neste passo") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# O QUE ACONTECE COM O MODELO FINAL
boost1_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,P1, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Observado vs Esperado (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# Gráfico de resíduos
boost1_r <- ggplot(df, aes(x,r1)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Gráfico de resíduos (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
ggpubr::ggarrange(boost1_r_vs_E, boost1_O_vs_E, boost1_r,
# labels = c("A", "B"),
ncol = 3, nrow = 1)
tree2 <- rpart(r1~x,
data=df,
control=rpart.control(maxdepth = 2, cp=0))
df['p2'] = predict(tree2, df) # predito da árvore tree2
df['P2'] = df$P1 + df$p2      # predito do boosting neste passo
df['r2'] = df$r1 - df$p2      # resíduo da árvore neste passo (resíduo do boosting)
# Gráfico da primeira iteração de boosting manual
# O QUE O MODELO ESTÁ FAZENDO
boost2_r_vs_E <- ggplot(df, aes(x,r1)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,p2, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Variável resposta neste passo") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y(i)") +
scale_x_continuous(name= "x")
# O QUE ACONTECE COM O MODELO FINAL
boost2_O_vs_E <- ggplot(df, aes(x,y)) +
geom_point(alpha=.7, size=.5, aes(colour='Observado')) +
geom_path(aes(x,P2, colour='Esperado')) + #Ploting
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Observado vs Esperado (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "y") +
scale_x_continuous(name= "x")
# Gráfico de resíduos
boost2_r <- ggplot(df, aes(x,r2)) +
geom_point(alpha=.7, size=.5, aes(colour='Resíduo')) +
scale_color_viridis(discrete=TRUE, begin=0, end=.8, name = "Dado: ") +
labs(title="Gráfico de resíduos (final)") +
theme_bw() +
theme(legend.position="bottom") +
scale_y_continuous(name= "r") +
scale_x_continuous(name= "x")
boost2_O_vs_E
ggpubr::ggarrange(boost2_r_vs_E, boost2_O_vs_E, boost2_r,
# labels = c("A", "B"),
ncol = 3, nrow = 1)
set.seed(2360873)
# parâmetros do trainControl
#number: number of folds or resampling iterations
#repeats: for repeated k-fold cross-validation, the number of complete sets of folds to compute
tempo_ini <- Sys.time()
controle <- caret::trainControl(
"cv",
number = 10,
summaryFunction = twoClassSummary, # Função de avaliação de performance
classProbs = TRUE # Necessário para calcular a curva ROC
)
modelo <- caret::train(
Survived ~.,
data = treino,
method = "xgbTree",
trControl = controle,
tuneGrid = NULL,
verbosity = 0)
modelo
tempo_fim <- Sys.time()
tempo_fim - tempo_ini
avalia(modelo)
# Base de treino
avalia <- function(modelo, nome_modelo="modelo"){
p_treino <- predict(modelo, treino, type='prob') # Probabilidade predita
c_treino <- predict(modelo, treino)              # Classificação
#Base de teste
p_teste <- predict(modelo, teste, type='prob')
c_teste <- predict(modelo, teste)
# Data frame de avaliação (Treino)
aval_treino <- data.frame(obs=treino$Survived,
pred=c_treino,
Y = p_treino[,2],
N = 1-p_treino[,2]
)
# Data frame de avaliação (Teste)
aval_teste <- data.frame(obs=teste$Survived,
pred=c_teste,
Y = p_teste[,2],
N = 1-p_teste[,2]
)
tcs_treino <- caret::twoClassSummary(aval_treino,
lev=levels(aval_treino$obs))
tcs_teste <- caret::twoClassSummary(aval_teste,
lev=levels(aval_teste$obs))
##########################
# Curva ROC              #
CurvaROC <- ggplot2::ggplot(aval_teste, aes(d = obs, m = Y, colour='1')) +
plotROC::geom_roc(n.cuts = 0, color="blue") +
plotROC::geom_roc(data=aval_treino,
aes(d = obs, m = Y, colour='1'),
n.cuts = 0, color = "red") +
scale_color_viridis_d(direction = -1, begin=0, end=.25) +
theme(legend.position = "none") +
ggtitle(paste("Curva ROC | ", nome_modelo, " | AUC-treino=",
percent(tcs_treino[1]),
"| AUC_teste = ",
percent(tcs_teste[1]))
)
print('Avaliação base de treino')
print(tcs_treino)
print('Avaliação base de teste')
print(tcs_teste)
CurvaROC
}
avalia(treino_rf)
avalia(treino_rf, nome_modelo="Random Forest")
avalia(gridsearch_rf, nome_modelo='RF Tunado')
avalia(modelo, nome_modelo="XGBoosting")
load("/Volumes/GoogleDrive-105296192289087716243/Meu Drive/Pecege/OMML2/OMML2_proj/titanic.Rda")
########################
# Instalação de pacotes
load("titanic.Rda")
# Acurácia
acuracia_treino_rf <- confusionMatrix(rf_p_treino[,2], treino$Survived)$overall[['Accuracy']]
# Acurácia
acuracia_treino_rf <- confusionMatrix(rf_p_treino[,2], treino$Survived)$overall[['Accuracy']]
# Acurácia
rf_p_treino[,2]
# Acurácia
rf_p_treino[,2] %>% head
# Acurácia
rf_p_treino[,2] %>% dim
acuracia_treino_rf <- confusionMatrix(rf_p_treino[,2], treino$Survived)$overall[['Accuracy']]
acuracia_treino_rf <- confusionMatrix(rf_c_treino, treino$Survived)$overall[['Accuracy']]
# Acurácia
acuracia_treino_rf
?milticlass.roc
?milticlass.roc
update.packages(ask = FALSE, checkBuilt = TRUE)
library(tinytex)
tinytex::tlmgr_update()
options(tinytex.verbose = TRUE)
